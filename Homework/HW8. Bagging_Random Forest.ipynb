{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bagging homework.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reesha-rsh/MLb4/blob/main/Homework/HW8.%20Bagging_Random%20Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 1. Use any binary classification dataset\n",
        "2. Define validation strategy and use it for all next steps without changes\n",
        "3. Train decision tree model and estimate performance on validation"
      ],
      "metadata": {
        "id": "prVttCvhr4j_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Validation approach: We have a small amount of data so I will use a **K Fold** method\n",
        "*   Metric: I plan to optimize **fbeta score** with beta 0.5 to give more weight for precision, thus minimizing false positives - reducing the prediction that a passenger survived when he actually did not.\n",
        "\n"
      ],
      "metadata": {
        "id": "9-nzJAuFsUk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_full = pd.read_csv(\"/content/drive/MyDrive/MLb4/EDA Titanic/train.csv\")\n",
        "test_full = pd.read_csv(\"/content/drive/MyDrive/MLb4/EDA Titanic/test.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J_TyHYFr5mz",
        "outputId": "7c1ff813-6d7e-4387-a35b-3cb998f0d58b"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(df,age_median,fare_median):\n",
        "  useless_features = ['Name','Ticket','Cabin']\n",
        "  data_cleaned = df\n",
        "  data_cleaned = data_cleaned.drop(columns = useless_features)\n",
        "\n",
        "  # generate binary values using get_dummies\n",
        "  data_cleaned = pd.get_dummies(data_cleaned, columns=['Sex'],prefix=[\"Sex\"])\n",
        "  data_cleaned = pd.get_dummies(data_cleaned, columns=['Embarked'],prefix=[\"Embarked\"])\n",
        "\n",
        "  # Check for NaN values in the DataFrame\n",
        "  nan_mask = data_cleaned.isnull()\n",
        "  # Count the number of NaN values in each column\n",
        "  nan_count_per_column = data_cleaned.isnull().sum()\n",
        "\n",
        "  data_cleaned['Age'] = data_cleaned['Age'].fillna(age_median)\n",
        "  data_cleaned['Fare'] = data_cleaned['Fare'].fillna(fare_median)\n",
        "\n",
        "  return data_cleaned\n"
      ],
      "metadata": {
        "id": "0ffTCrWwsHXY"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_columns = ['Pclass',\t'Age',\t'SibSp',\t'Parch',\t'Fare',\t'Sex_female',\t'Sex_male',\t'Embarked_C',\t'Embarked_Q',\t'Embarked_S']"
      ],
      "metadata": {
        "id": "5kw_X7rzsJSW"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get medians that will fill NaNs in generate func\n",
        "age_median = train_full['Age'].median()\n",
        "fare_median = train_full['Fare'].median()"
      ],
      "metadata": {
        "id": "OWmmUDuOsKx5"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = generate(train_full,age_median=age_median,fare_median=fare_median)\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "UA9XIOaqsL9u",
        "outputId": "1ac610bc-1771-42da-c09b-5fe6ccc365c8"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  Sex_female  \\\n",
              "0              1         0       3  22.0      1      0   7.2500           0   \n",
              "1              2         1       1  38.0      1      0  71.2833           1   \n",
              "2              3         1       3  26.0      0      0   7.9250           1   \n",
              "3              4         1       1  35.0      1      0  53.1000           1   \n",
              "4              5         0       3  35.0      0      0   8.0500           0   \n",
              "..           ...       ...     ...   ...    ...    ...      ...         ...   \n",
              "886          887         0       2  27.0      0      0  13.0000           0   \n",
              "887          888         1       1  19.0      0      0  30.0000           1   \n",
              "888          889         0       3  28.0      1      2  23.4500           1   \n",
              "889          890         1       1  26.0      0      0  30.0000           0   \n",
              "890          891         0       3  32.0      0      0   7.7500           0   \n",
              "\n",
              "     Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
              "0           1           0           0           1  \n",
              "1           0           1           0           0  \n",
              "2           0           0           0           1  \n",
              "3           0           0           0           1  \n",
              "4           1           0           0           1  \n",
              "..        ...         ...         ...         ...  \n",
              "886         1           0           0           1  \n",
              "887         0           0           0           1  \n",
              "888         0           0           0           1  \n",
              "889         1           1           0           0  \n",
              "890         1           0           1           0  \n",
              "\n",
              "[891 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-9ca658a2-915d-4d94-9924-d259d109ee11\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Sex_female</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ca658a2-915d-4d94-9924-d259d109ee11')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-52164ce3-6c3c-47b1-8b41-76ac8b8464f0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-52164ce3-6c3c-47b1-8b41-76ac8b8464f0')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-52164ce3-6c3c-47b1-8b41-76ac8b8464f0 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ca658a2-915d-4d94-9924-d259d109ee11 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ca658a2-915d-4d94-9924-d259d109ee11');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_state = 42"
      ],
      "metadata": {
        "id": "sex7kbQwsTi-"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "AFK96rfx1qDb"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_validation, y_train, y_validation = train_test_split(train[features_columns], train['Survived'], test_size=0.2, random_state=random_state, stratify=train['Survived'])\n"
      ],
      "metadata": {
        "id": "ZInb3Rpw2G_0"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = train[features_columns]\n",
        "# y_train = train['Survived']"
      ],
      "metadata": {
        "id": "yp_2dCMMuqe-"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import make_scorer, fbeta_score, classification_report, accuracy_score\n",
        "from sklearn import metrics\n"
      ],
      "metadata": {
        "id": "5ln5QTEhseo2"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the StratifiedKFold object\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)"
      ],
      "metadata": {
        "id": "ISAPU70CscfS"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the custom scoring function with the desired beta value\n",
        "beta = 0.5\n",
        "custom_scorer = make_scorer(fbeta_score, beta=beta)"
      ],
      "metadata": {
        "id": "OssvR8VFsaCL"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import make_scorer, fbeta_score\n",
        "\n",
        "\n",
        "\n",
        "# Define the DecisionTreeClassifier model\n",
        "classifier = DecisionTreeClassifier(random_state=random_state)\n",
        "\n",
        "# Define the hyperparameter grid to search over\n",
        "param_grid = {\n",
        "    'criterion': ['gini'],\n",
        "    'splitter': ['random'],\n",
        "    'max_depth': [None, 3, 5, 7, 9, 11],\n",
        "    'min_samples_leaf': [1,  3,  5,  7,  9,  11],\n",
        "    'max_features': [ 1,  3,  5,  7,  9,  10],\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "\n",
        "# Initialize the GridSearchCV object with the DecisionTreeClassifier, hyperparameter grid, and custom scorer\n",
        "grid_search = GridSearchCV(classifier, param_grid, scoring=custom_scorer, cv=skf)\n",
        "\n",
        "# Perform grid search to find the best hyperparameters\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the corresponding model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Optionally, you can evaluate the model on the full data using the F-beta score with beta=0.1\n",
        "y_pred = best_model.predict(X_validation)\n",
        "\n",
        "fbeta = fbeta_score(y_validation, y_pred, beta=beta)\n",
        "accuracy = accuracy_score(y_validation, y_pred)\n",
        "\n",
        "print(\"F-beta Score (beta={}): {:.4f}\".format(beta, fbeta))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "print(metrics.classification_report(y_validation, y_pred))\n",
        "print(metrics.confusion_matrix(y_validation, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhjMorzGsjBd",
        "outputId": "05b45397-7fae-451f-8e5e-5183000732cc"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_features': 3, 'min_samples_leaf': 9, 'splitter': 'random'}\n",
            "F-beta Score (beta=0.5): 0.7736\n",
            "Accuracy: 0.7989\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.93      0.85       110\n",
            "           1       0.84      0.59      0.69        69\n",
            "\n",
            "    accuracy                           0.80       179\n",
            "   macro avg       0.81      0.76      0.77       179\n",
            "weighted avg       0.80      0.80      0.79       179\n",
            "\n",
            "[[102   8]\n",
            " [ 28  41]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Train bagging model with decision tree as a base model and estimate performance on validation"
      ],
      "metadata": {
        "id": "zlt_4XlqviTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n"
      ],
      "metadata": {
        "id": "UcyBLQj0wd2L"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    \"max_features\": [1,  3,  5,  7,  9,  10],\n",
        "    \"max_samples\": [0.7, 0.8, 0.9],\n",
        "    \"estimator__max_depth\": [None, 3, 5, 7, 9, 11],\n",
        "    \"estimator__min_samples_leaf\": [1,  3,  5,  7,  9,  11],\n",
        "    'estimator__criterion': ['gini'],\n",
        "    'estimator__splitter': ['random'],\n",
        "    'estimator__class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=random_state)\n",
        "bg = BaggingClassifier(dt, random_state=random_state, n_estimators=25)\n",
        "\n",
        "bag_grid_search = GridSearchCV(bg, parameters, scoring=custom_scorer, cv=skf)\n",
        "\n",
        "\n",
        "# Perform grid search to find the best hyperparameters\n",
        "bag_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the corresponding model\n",
        "best_params = bag_grid_search.best_params_\n",
        "best_model = bag_grid_search.best_estimator_\n",
        "\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Optionally, you can evaluate the model on the full data using the F-beta score with beta=0.1\n",
        "y_pred = best_model.predict(X_validation)\n",
        "\n",
        "fbeta = fbeta_score(y_validation, y_pred, beta=beta)\n",
        "accuracy = accuracy_score(y_validation, y_pred)\n",
        "\n",
        "print(\"F-beta Score (beta={}): {:.4f}\".format(beta, fbeta))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "print(metrics.classification_report(y_validation, y_pred))\n",
        "print(metrics.confusion_matrix(y_validation, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok_Zjsn-vjmR",
        "outputId": "b8b081b9-33d3-4d22-c085-5b43415e8ed6"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'estimator__class_weight': 'balanced', 'estimator__criterion': 'gini', 'estimator__max_depth': 7, 'estimator__min_samples_leaf': 1, 'estimator__splitter': 'random', 'max_features': 9, 'max_samples': 0.8}\n",
            "F-beta Score (beta=0.5): 0.7348\n",
            "Accuracy: 0.7877\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.86      0.83       110\n",
            "           1       0.75      0.67      0.71        69\n",
            "\n",
            "    accuracy                           0.79       179\n",
            "   macro avg       0.78      0.77      0.77       179\n",
            "weighted avg       0.79      0.79      0.78       179\n",
            "\n",
            "[[95 15]\n",
            " [23 46]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RANDOM FOREST"
      ],
      "metadata": {
        "id": "bZjVu-6e3SCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "xtIj2iqX41Ma"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    \"max_features\": [1,  3,  5,  7,  9,  10],\n",
        "    \"max_samples\": [0.7, 0.8, 0.9],\n",
        "    \"max_depth\": [None, 3, 5, 7, 9, 11],\n",
        "    \"min_samples_leaf\": [1,  3,  5,  7,  9,  11],\n",
        "    'criterion': ['gini'],\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=25, random_state=random_state, n_jobs=-1, oob_score=True)\n",
        "forest_grid_search = GridSearchCV(rfc, parameters, scoring=custom_scorer, cv=skf)\n",
        "\n",
        "# Perform grid search to find the best hyperparameters\n",
        "forest_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the corresponding model\n",
        "best_params = forest_grid_search.best_params_\n",
        "best_model = forest_grid_search.best_estimator_\n",
        "\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Optionally, you can evaluate the model on the full data using the F-beta score with beta=0.1\n",
        "y_pred = best_model.predict(X_validation)\n",
        "\n",
        "fbeta = fbeta_score(y_validation, y_pred, beta=beta)\n",
        "accuracy = accuracy_score(y_validation, y_pred)\n",
        "\n",
        "print(\"F-beta Score (beta={}): {:.4f}\".format(beta, fbeta))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "print(metrics.classification_report(y_validation, y_pred))\n",
        "print(metrics.confusion_matrix(y_validation, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxzd9DVI4IO6",
        "outputId": "201f2f2a-44c8-4f9b-e01c-67e910b092b1"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_features': 3, 'max_samples': 0.7, 'min_samples_leaf': 1}\n",
            "F-beta Score (beta=0.5): 0.7475\n",
            "Accuracy: 0.7933\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.84       110\n",
            "           1       0.78      0.65      0.71        69\n",
            "\n",
            "    accuracy                           0.79       179\n",
            "   macro avg       0.79      0.77      0.77       179\n",
            "weighted avg       0.79      0.79      0.79       179\n",
            "\n",
            "[[97 13]\n",
            " [24 45]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMms33J4jeDZ"
      },
      "source": [
        "\n",
        "# 5. Write your own bagging implementation:\n",
        "  <br>5.1. Define init for our CustomBaggingClassifier\n",
        "  <br>5.2. Write fit as described in lecture: divide train data on n parts (`n_estimators` in CustomBaggingClassifier), train `base_estimator` on each part and save these models inside class\n",
        "  <br>5.3. For predictions we should use all saved models and combine their predictions (as voting)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "zNO0I89bhHn0"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "fcLfBRrXk3r2"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import clone"
      ],
      "metadata": {
        "id": "sfSS2RC8IZqJ"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_trees(tree1, tree2):\n",
        "    if hash(tree1.__dict__.values())==hash(tree2.__dict__.values()):\n",
        "        # the trees have both been trained\n",
        "        if tree1.tree_ != None and tree2.tree_ != None:\n",
        "            try: # the tree values are matching arrays\n",
        "                return np.array_equal(tree1.tree_.value, tree2.tree_.value)\n",
        "            except: # they do not match\n",
        "                return False\n",
        "        elif tree1.tree_ != None or tree2.tree_ != None:\n",
        "            # XOR of the trees is not trained\n",
        "            return False\n",
        "        else: # Neither has been trained\n",
        "            return True\n",
        "    else: # the params are different\n",
        "        return False"
      ],
      "metadata": {
        "id": "49Z_AD4goQjL"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBaggingClassifier:\n",
        "    def __init__(self, base_estimator, n_estimators, max_samples=1.0, max_features=1.0, random_state=None):\n",
        "        self.base_estimator = base_estimator\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_samples = max_samples\n",
        "        self.max_features = max_features\n",
        "        self.random_state = random_state\n",
        "        self.estimators = []\n",
        "\n",
        "\n",
        "\n",
        "    def bootstrap_sampling(self, X, y):\n",
        "        # Implement bootstrap sampling to randomly select subsets of data\n",
        "        num_samples = X.shape[0]\n",
        "        if isinstance(self.max_samples, int):\n",
        "            sample_size = self.max_samples\n",
        "        elif isinstance(self.max_samples, float):\n",
        "            sample_size = int(self.max_samples * num_samples)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid type for max_samples. It must be int or float.\")\n",
        "\n",
        "        n_features = X.shape[1]\n",
        "        if isinstance(self.max_features, int):\n",
        "            max_features = self.max_features\n",
        "        elif isinstance(self.max_features, float):\n",
        "            max_features = max(1, int(self.max_features * n_features))\n",
        "        else:\n",
        "            raise ValueError(\"Invalid type for max_features. It must be int or float.\")\n",
        "\n",
        "        # np.random.seed(self.random_state)\n",
        "        sample_indices = np.random.choice(num_samples, size=sample_size, replace=True)\n",
        "        sample_features = np.random.choice(n_features, size=max_features, replace=True)\n",
        "\n",
        "        X_sampled = X.iloc[sample_indices,sample_features]\n",
        "        y_sampled = y.iloc[sample_indices]\n",
        "        return X_sampled, y_sampled\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        for _ in range(self.n_estimators):\n",
        "            # Get a random subset of the data using bootstrap sampling\n",
        "            X_sampled, y_sampled = self.bootstrap_sampling(X, y)\n",
        "\n",
        "            # Train a new base estimator and store it in the list\n",
        "            estimator = clone(self.base_estimator)\n",
        "            estimator.fit(X_sampled, y_sampled)\n",
        "\n",
        "            # Check if estimators are the same\n",
        "            if self.estimators:\n",
        "              prev_estimator = self.estimators[-1]\n",
        "              if compare_trees(estimator, self.estimators[-1]):\n",
        "                raise ValueError(\"Estimators are the same.\")\n",
        "\n",
        "            self.estimators.append(estimator)\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Make predictions using majority voting for classification\n",
        "        predictions = np.zeros((X.shape[0], len(self.estimators)))\n",
        "\n",
        "        for index, estimator in enumerate(self.estimators):\n",
        "\n",
        "            predictions[:, index] = estimator.predict(X.loc[:,estimator.feature_names_in_])\n",
        "\n",
        "        # Take the majority vote to make the final prediction\n",
        "        final_predictions = np.apply_along_axis(lambda x: np.bincount(x.astype('int')).argmax(), axis=1, arr=predictions)\n",
        "\n",
        "        return final_predictions\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {\n",
        "            'base_estimator': self.base_estimator,\n",
        "            'n_estimators': self.n_estimators,\n",
        "            'max_samples': self.max_samples,\n",
        "            'max_features': self.max_features,\n",
        "            'random_state': self.random_state\n",
        "        }\n",
        "\n",
        "    def set_params(self, **params):\n",
        "        for param, value in params.items():\n",
        "            setattr(self, param, value)\n",
        "        return self\n"
      ],
      "metadata": {
        "id": "4dFu1IPnG7T7"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    \"max_features\": [  3 ],\n",
        "    \"max_samples\": [0.7],\n",
        "    \"base_estimator__max_depth\": [None],\n",
        "    \"base_estimator__min_samples_leaf\": [1],\n",
        "    'base_estimator__criterion': ['gini'],\n",
        "    'base_estimator__splitter': ['random'],\n",
        "    'base_estimatorr__class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "cbg = CustomBaggingClassifier(dt, n_estimators=2)\n",
        "\n",
        "cbag_grid_search = GridSearchCV(cbg, parameters, scoring=custom_scorer, cv=skf)\n",
        "\n",
        "\n",
        "# Perform grid search to find the best hyperparameters\n",
        "cbag_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the corresponding model\n",
        "best_params = cbag_grid_search.best_params_\n",
        "best_model = cbag_grid_search.best_estimator_\n",
        "\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Optionally, you can evaluate the model on the full data using the F-beta score with beta=0.1\n",
        "y_pred = best_model.predict(X_validation)\n",
        "\n",
        "fbeta = fbeta_score(y_validation, y_pred, beta=beta)\n",
        "accuracy = accuracy_score(y_validation, y_pred)\n",
        "\n",
        "print(\"F-beta Score (beta={}): {:.4f}\".format(beta, fbeta))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "print(metrics.classification_report(y_validation, y_pred))\n",
        "print(metrics.confusion_matrix(y_validation, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL0jBUWxSa9z",
        "outputId": "69dd7f5e-ceb4-45c2-888e-4e452e27375b"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': None, 'base_estimator__min_samples_leaf': 1, 'base_estimator__splitter': 'random', 'base_estimatorr__class_weight': 'balanced', 'max_features': 3, 'max_samples': 0.7}\n",
            "F-beta Score (beta=0.5): 0.5491\n",
            "Accuracy: 0.6816\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.94      0.78       110\n",
            "           1       0.73      0.28      0.40        69\n",
            "\n",
            "    accuracy                           0.68       179\n",
            "   macro avg       0.70      0.61      0.59       179\n",
            "weighted avg       0.70      0.68      0.64       179\n",
            "\n",
            "[[103   7]\n",
            " [ 50  19]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbag_grid_search.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1zb18ovEJ5h",
        "outputId": "5f69d246-5084-4253-ed99-2ec6633f94b4"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6564976751125358"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    \"max_features\": [1,  3,  5,  7,  9,  10],\n",
        "    \"max_samples\": [0.7, 0.8, 0.9],\n",
        "    \"base_estimator__max_depth\": [None, 3, 5, 7, 9, 11],\n",
        "    \"base_estimator__min_samples_leaf\": [1,  3,  5,  7,  9,  11],\n",
        "    'base_estimator__criterion': ['gini'],\n",
        "    'base_estimator__splitter': ['random'],\n",
        "    'base_estimatorr__class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=random_state)\n",
        "cbg = CustomBaggingClassifier(dt, random_state=random_state, n_estimators=25)\n",
        "\n",
        "cbag_grid_search = GridSearchCV(cbg, parameters, scoring=custom_scorer, cv=skf)\n",
        "\n",
        "\n",
        "# Perform grid search to find the best hyperparameters\n",
        "cbag_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the corresponding model\n",
        "best_params = cbag_grid_search.best_params_\n",
        "best_model = cbag_grid_search.best_estimator_\n",
        "\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Optionally, you can evaluate the model on the full data using the F-beta score with beta=0.1\n",
        "y_pred = best_model.predict(X_validation)\n",
        "\n",
        "fbeta = fbeta_score(y_validation, y_pred, beta=beta)\n",
        "accuracy = accuracy_score(y_validation, y_pred)\n",
        "\n",
        "print(\"F-beta Score (beta={}): {:.4f}\".format(beta, fbeta))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "print(metrics.classification_report(y_validation, y_pred))\n",
        "print(metrics.confusion_matrix(y_validation, y_pred))\n"
      ],
      "metadata": {
        "id": "jOXXiZT4LrlU",
        "outputId": "9961c3c2-04f8-4242-9f2a-1b44242b2540",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 3, 'base_estimator__min_samples_leaf': 3, 'base_estimator__splitter': 'random', 'base_estimatorr__class_weight': 'balanced', 'max_features': 7, 'max_samples': 0.7}\n",
            "F-beta Score (beta=0.5): 0.7439\n",
            "Accuracy: 0.7877\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.84       110\n",
            "           1       0.78      0.62      0.69        69\n",
            "\n",
            "    accuracy                           0.79       179\n",
            "   macro avg       0.79      0.76      0.77       179\n",
            "weighted avg       0.79      0.79      0.78       179\n",
            "\n",
            "[[98 12]\n",
            " [26 43]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Compare performance of sklearn bagging model with your own implementation"
      ],
      "metadata": {
        "id": "fsNWrra-_van"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CustomBaggingClassifier**\n",
        "\n",
        "Best Hyperparameters: {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': None, 'base_estimator__min_samples_leaf': 1, 'base_estimator__splitter': 'random', 'base_estimatorr__class_weight': 'balanced', 'max_features': 5, 'max_samples': 0.9}\n",
        "F-beta Score (beta=0.5): 0.7935\n",
        "Accuracy: 0.8103\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.79      0.94      0.86       549\n",
        "           1       0.86      0.60      0.71       342\n",
        "\n",
        "    accuracy                           0.81       891\n",
        "   macro avg       0.83      0.77      0.78       891\n",
        "weighted avg       0.82      0.81      0.80       891\n",
        "\n",
        "[[516  33]\n",
        " [136 206]]"
      ],
      "metadata": {
        "id": "S35q6cG8T_5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BaggingClassifier\n",
        "\n",
        "Best Hyperparameters: {'estimator__class_weight': 'balanced', 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__min_samples_leaf': 1, 'estimator__splitter': 'random', 'max_features': 5, 'max_samples': 0.7}\n",
        "F-beta Score (beta=0.5): 0.9102\n",
        "Accuracy: 0.9147\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.91      0.96      0.93       549\n",
        "           1       0.93      0.84      0.88       342\n",
        "\n",
        "    accuracy                           0.91       891\n",
        "   macro avg       0.92      0.90      0.91       891\n",
        "weighted avg       0.92      0.91      0.91       891\n",
        "\n",
        "[[527  22]\n",
        " [ 54 288]]"
      ],
      "metadata": {
        "id": "_90_xHDiUM7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have a really big gap between Custom and sklearn bagging classifiers. I don't understand what I am missing in my custom implementation"
      ],
      "metadata": {
        "id": "xar_E9P6TVT_"
      }
    }
  ]
}