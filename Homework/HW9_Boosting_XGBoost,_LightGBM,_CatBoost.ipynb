{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPO8ryxrZINqRIx5XptTFKo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reesha-rsh/MLb4/blob/main/Homework/HW9_Boosting_XGBoost%2C_LightGBM%2C_CatBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Homework:\n",
        "\n",
        "- use the dataset and validation approach which you used for previous homeworks\n",
        "- train xgboost, lightgbm, and catboost models and find the best hyperparameters for each algorithm\n",
        "- compare results between them and previously trained random forest"
      ],
      "metadata": {
        "id": "gEOgD5Ja2Ob1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Init"
      ],
      "metadata": {
        "id": "OZIy0wxO5Q_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pandas==1.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldgzmFwrcw37",
        "outputId": "96ab603a-be31-4ca0-b58d-6e05009d1d55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas==1.2\n",
            "  Downloading pandas-1.2.0.tar.gz (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.2) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from pandas==1.2) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.3->pandas==1.2) (1.16.0)\n",
            "Building wheels for collected packages: pandas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63IgV7lh2Bks"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import make_scorer, fbeta_score, classification_report, accuracy_score\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_full = pd.read_csv(\"/content/drive/MyDrive/MLb4/EDA Titanic/train.csv\")\n",
        "test_full = pd.read_csv(\"/content/drive/MyDrive/MLb4/EDA Titanic/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_state = 42"
      ],
      "metadata": {
        "id": "TxMq2dAL3Fij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(df,age_median,fare_median):\n",
        "  useless_features = ['Name','Ticket','Cabin']\n",
        "  data_cleaned = df\n",
        "  data_cleaned = data_cleaned.drop(columns = useless_features)\n",
        "\n",
        "  # generate binary values using get_dummies\n",
        "  data_cleaned = pd.get_dummies(data_cleaned, columns=['Sex'],prefix=[\"Sex\"])\n",
        "  data_cleaned = pd.get_dummies(data_cleaned, columns=['Embarked'],prefix=[\"Embarked\"])\n",
        "\n",
        "  # Check for NaN values in the DataFrame\n",
        "  nan_mask = data_cleaned.isnull()\n",
        "  # Count the number of NaN values in each column\n",
        "  nan_count_per_column = data_cleaned.isnull().sum()\n",
        "\n",
        "  data_cleaned['Age'] = data_cleaned['Age'].fillna(age_median)\n",
        "  data_cleaned['Fare'] = data_cleaned['Fare'].fillna(fare_median)\n",
        "\n",
        "  return data_cleaned\n"
      ],
      "metadata": {
        "id": "ERoq9Nnv2xBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_features = ['PassengerId', 'Survived']"
      ],
      "metadata": {
        "id": "F3H24ogz24AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get medians that will fill NaNs in generate func\n",
        "age_median = train_full['Age'].median()\n",
        "print(age_median)\n",
        "fare_median = train_full['Fare'].median()\n",
        "print(fare_median)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "OwF8O6rh23jf",
        "outputId": "b9145809-7666-4b4f-f5d1-390bb422805b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-35b4e4c38284>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get medians that will fill NaNs in generate func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mage_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage_median\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfare_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Fare'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfare_median\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_full' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = generate(train_full,age_median=age_median,fare_median=fare_median)\n",
        "print(train)\n",
        "\n",
        "X_train = train.drop(not_features, axis = 1)\n",
        "y_train = train['Survived']"
      ],
      "metadata": {
        "id": "p_iH14z43CbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the StratifiedKFold object\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)"
      ],
      "metadata": {
        "id": "dFbDZVZw3pwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the custom scoring function with the desired beta value\n",
        "beta = 0.5\n",
        "custom_scorer = make_scorer(fbeta_score, beta=beta)"
      ],
      "metadata": {
        "id": "QoYN1zO33roU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#XGBoost"
      ],
      "metadata": {
        "id": "U-tXhUix5ULR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "k-_IOynX5czb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_train = xgb.DMatrix(X_train, y_train, feature_names=X_train.columns)\n",
        "\n",
        "num_rounds = 10000\n",
        "param_grid = {\n",
        "    #default\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eta\": 0.01,\n",
        "    \"verbosity\": 0,\n",
        "    \"nthread\": 10,\n",
        "    \"random_seed\": random_state,\n",
        "    \"eval_metric\": \"auc\",\n",
        "\n",
        "    # regularization parameters\n",
        "    \"max_leaves\": 32,\n",
        "    \"subsample\": 0.7,\n",
        "    \"colsample_bytree\": 0.7,\n",
        "\n",
        "    #lightgbm approach\n",
        "    \"tree_method\": \"hist\",\n",
        "    \"grow_policy\": \"lossguide\"\n",
        "}\n",
        "\n",
        "results = xgb.cv(param_grid, xgb_train, num_rounds, early_stopping_rounds=50,folds=skf, verbose_eval=20)"
      ],
      "metadata": {
        "id": "iChPpOJuHBmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    #default\n",
        "    \"objective\": [\"binary:logistic\"],\n",
        "    \"eta\": [0.01, 0.05],\n",
        "    \"verbosity\": [0],\n",
        "    \"nthread\": [10],\n",
        "    \"random_seed\": [random_state],\n",
        "\n",
        "\n",
        "    # regularization parameters\n",
        "    \"max_leaves\": [16, 32, 64],\n",
        "    \"subsample\": [0.7, 0.8, 0.9, 1.0],\n",
        "    \"colsample_bytree\": [0.7, 0.8, 0.9, 1.0],\n",
        "\n",
        "    #lightgbm approach\n",
        "    \"tree_method\": [\"hist\"],\n",
        "    \"grow_policy\": [\"lossguide\"]\n",
        "}"
      ],
      "metadata": {
        "id": "L53Bct8MNYfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',silent=True, nthread=1)\n",
        "\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "grid_search = GridSearchCV(xgb_model, param_grid, scoring=custom_scorer, cv=skf )\n",
        "\n",
        "# Perform grid search to find the best hyperparameters\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the corresponding model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Best Score:\", best_score)"
      ],
      "metadata": {
        "id": "kQyhvPeF8Qyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGBM"
      ],
      "metadata": {
        "id": "DeI9efrdX6k5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "4Cs9nADcZCRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "parameters = {\n",
        "    #default\n",
        "    \"objective\": \"binary\",\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"num_threads\": 10,\n",
        "    \"metric\": \"auc\",\n",
        "    \"seed\": 42,\n",
        "\n",
        "    #regularization\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"subsample\": 0.8,\n",
        "    \"subsample_freq\": 1,\n",
        "    \"min_data_in_leaf\": 50\n",
        "}\n",
        "\n",
        "\n",
        "n_rounds = 10000\n",
        "\n",
        "lgb_train = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
        "result = lgb.cv(parameters, lgb_train, n_rounds, folds=skf, early_stopping_rounds=50, verbose_eval=100, eval_train_metric=True)"
      ],
      "metadata": {
        "id": "zo1t7QmxYwHd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}