{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkCl1y86lesrEOEvfpaDU9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reesha-rsh/MLb4/blob/main/Homework/HW9_Boosting_XGBoost%2C_LightGBM%2C_CatBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Homework:\n",
        "\n",
        "- use the dataset and validation approach which you used for previous homeworks\n",
        "- train xgboost, lightgbm, and catboost models and find the best hyperparameters for each algorithm\n",
        "- compare results between them and previously trained random forest"
      ],
      "metadata": {
        "id": "gEOgD5Ja2Ob1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Init"
      ],
      "metadata": {
        "id": "OZIy0wxO5Q_K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "63IgV7lh2Bks",
        "outputId": "e93fafad-3fd2-435a-fac5-31f813001c9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import make_scorer, fbeta_score, classification_report, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_full = pd.read_csv(\"/content/drive/MyDrive/MLb4/EDA Titanic/train.csv\")\n",
        "test_full = pd.read_csv(\"/content/drive/MyDrive/MLb4/EDA Titanic/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_state = 42"
      ],
      "metadata": {
        "id": "TxMq2dAL3Fij"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(df,age_median,fare_median):\n",
        "  useless_features = ['Name','Ticket','Cabin']\n",
        "  data_cleaned = df\n",
        "  data_cleaned = data_cleaned.drop(columns = useless_features)\n",
        "\n",
        "  # generate binary values using get_dummies\n",
        "  data_cleaned = pd.get_dummies(data_cleaned, columns=['Sex'],prefix=[\"Sex\"])\n",
        "  data_cleaned = pd.get_dummies(data_cleaned, columns=['Embarked'],prefix=[\"Embarked\"])\n",
        "\n",
        "  # Check for NaN values in the DataFrame\n",
        "  nan_mask = data_cleaned.isnull()\n",
        "  # Count the number of NaN values in each column\n",
        "  nan_count_per_column = data_cleaned.isnull().sum()\n",
        "\n",
        "  data_cleaned['Age'] = data_cleaned['Age'].fillna(age_median)\n",
        "  data_cleaned['Fare'] = data_cleaned['Fare'].fillna(fare_median)\n",
        "\n",
        "  return data_cleaned\n"
      ],
      "metadata": {
        "id": "ERoq9Nnv2xBB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_features = ['PassengerId', 'Survived']"
      ],
      "metadata": {
        "id": "F3H24ogz24AC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get medians that will fill NaNs in generate func\n",
        "age_median = train_full['Age'].median()\n",
        "print(age_median)\n",
        "fare_median = train_full['Fare'].median()\n",
        "print(fare_median)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwF8O6rh23jf",
        "outputId": "46844808-5070-4e4f-f1e7-ec0937699696"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28.0\n",
            "14.4542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = generate(train_full,age_median=age_median,fare_median=fare_median)\n",
        "print(train)\n",
        "\n",
        "X_train = train.drop(not_features, axis = 1)\n",
        "y_train = train['Survived']"
      ],
      "metadata": {
        "id": "p_iH14z43CbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96293b76-7c3f-4fde-e0a0-b8effd1baed6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  Sex_female  \\\n",
            "0              1         0       3  22.0      1      0   7.2500           0   \n",
            "1              2         1       1  38.0      1      0  71.2833           1   \n",
            "2              3         1       3  26.0      0      0   7.9250           1   \n",
            "3              4         1       1  35.0      1      0  53.1000           1   \n",
            "4              5         0       3  35.0      0      0   8.0500           0   \n",
            "..           ...       ...     ...   ...    ...    ...      ...         ...   \n",
            "886          887         0       2  27.0      0      0  13.0000           0   \n",
            "887          888         1       1  19.0      0      0  30.0000           1   \n",
            "888          889         0       3  28.0      1      2  23.4500           1   \n",
            "889          890         1       1  26.0      0      0  30.0000           0   \n",
            "890          891         0       3  32.0      0      0   7.7500           0   \n",
            "\n",
            "     Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
            "0           1           0           0           1  \n",
            "1           0           1           0           0  \n",
            "2           0           0           0           1  \n",
            "3           0           0           0           1  \n",
            "4           1           0           0           1  \n",
            "..        ...         ...         ...         ...  \n",
            "886         1           0           0           1  \n",
            "887         0           0           0           1  \n",
            "888         0           0           0           1  \n",
            "889         1           1           0           0  \n",
            "890         1           0           1           0  \n",
            "\n",
            "[891 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = generate(test_full,age_median=age_median,fare_median=fare_median)\n",
        "X_test = test.drop('PassengerId' , axis = 1)"
      ],
      "metadata": {
        "id": "9bx8vanYmCse"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the StratifiedKFold object\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)"
      ],
      "metadata": {
        "id": "dFbDZVZw3pwl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RANDOM FOREST"
      ],
      "metadata": {
        "id": "vTU4QK0Gp0x4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "ue3SnuxJp1dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    \"max_features\": [1,  3,  5,  7,  9,  10],\n",
        "    \"max_samples\": [0.7, 0.8, 0.9],\n",
        "    \"max_depth\": [None, 3, 5, 7, 9, 11],\n",
        "    \"min_samples_leaf\": [1,  3,  5,  7,  9,  11],\n",
        "    'criterion': ['gini'],\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=25, random_state=random_state, n_jobs=-1, oob_score=True)\n",
        "forest_grid_search = GridSearchCV(rfc, parameters, scoring='accuracy', cv=skf)\n",
        "\n",
        "# Perform grid search to find the best hyperparameters\n",
        "forest_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the corresponding model\n",
        "best_params = forest_grid_search.best_params_\n",
        "best_model = forest_grid_search.best_estimator_\n",
        "best_score = forest_grid_search.best_score_\n",
        "\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Accuracy: {:.4f}\".format(best_score))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kf9DspLp4IL",
        "outputId": "7a7fa664-53b1-4b98-8035-4e2eabb1d5fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 9, 'max_features': 7, 'max_samples': 0.8, 'min_samples_leaf': 3}\n",
            "Accuracy: 0.8451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_model.predict(X_test)\n",
        "submission_data = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': y_pred})\n",
        "submission_data.to_csv(\"/content/drive/MyDrive/MLb4/EDA Titanic/submissionRandomForest.csv\", index=False)"
      ],
      "metadata": {
        "id": "WwEzluiip7ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SUBMISSION SCORE:** 0.76555"
      ],
      "metadata": {
        "id": "XRIBVhakotyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#XGBoost"
      ],
      "metadata": {
        "id": "U-tXhUix5ULR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "k-_IOynX5czb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_train = xgb.DMatrix(X_train, y_train, feature_names=X_train.columns)\n",
        "\n",
        "num_rounds = 10000\n",
        "param = {\n",
        "    #default\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eta\": 0.01,\n",
        "    \"verbosity\": 0,\n",
        "    \"nthread\": 10,\n",
        "    \"random_seed\": random_state,\n",
        "    \"eval_metric\": \"error\",\n",
        "    # \"feval\": custom_scorer,\n",
        "\n",
        "\n",
        "    # regularization parameters\n",
        "    \"max_leaves\": 16,\n",
        "    \"subsample\": 0.7,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"gamma\": 0,\n",
        "    # \"min_child_weight\": 1,\n",
        "\n",
        "\n",
        "    #lightgbm approach\n",
        "    \"tree_method\": \"hist\",\n",
        "    \"grow_policy\": \"lossguide\"\n",
        "}\n",
        "\n",
        "results = xgb.cv(param, xgb_train, num_rounds, early_stopping_rounds=20,folds=skf, verbose_eval=100)\n",
        "best_score = 1-(results[\"test-error-mean\"].min())\n",
        "n_estimators  = int(len(results.index)* 1.1)\n",
        "print(\"Accuracy on validation: {:.4f}\".format(best_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN0aMStdPOwI",
        "outputId": "5ed74203-6996-4c46-b366-a0c01c88845e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-error:0.17368+0.00332\ttest-error:0.21100+0.01610\n",
            "[31]\ttrain-error:0.13608+0.00322\ttest-error:0.15939+0.02009\n",
            "Accuracy on validation: 0.8417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = xgb.XGBClassifier(\n",
        "    #default\n",
        "    objective= \"binary:logistic\",\n",
        "    eta= 0.01,\n",
        "    verbosity= 0,\n",
        "    nthread= 10,\n",
        "    random_seed= random_state,\n",
        "    eval_metric = \"error\",\n",
        "\n",
        "    n_estimators = n_estimators,\n",
        "\n",
        "\n",
        "    # regularization parameters\n",
        "    max_leaves= 16,\n",
        "    subsample= 0.7,\n",
        "    colsample_bytree= 0.9,\n",
        "    gamma= 0,\n",
        "    min_child_weight= 5,\n",
        "\n",
        "\n",
        "    #lightgbm approach\n",
        "    tree_method= \"hist\",\n",
        "    grow_policy= \"lossguide\"\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "submission_data = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': y_pred})\n",
        "submission_data.to_csv(\"/content/drive/MyDrive/MLb4/EDA Titanic/submissionXgb.csv\", index=False)"
      ],
      "metadata": {
        "id": "AxpiKb7tme3D"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SUBMISSION SCORE:** 0.77511"
      ],
      "metadata": {
        "id": "zkg8Dk5h3RLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGBM"
      ],
      "metadata": {
        "id": "DeI9efrdX6k5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "4Cs9nADcZCRe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    #default\n",
        "    \"objective\": \"binary\",\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"num_threads\": 10,\n",
        "    \"metric\": 'binary_error',\n",
        "\n",
        "    \"seed\":  [random_state],\n",
        "\n",
        "    #regularization\n",
        "    \"colsample_bytree\": 0.7,\n",
        "    \"subsample\": 0.7,\n",
        "    \"subsample_freq\": 1,\n",
        "    \"min_data_in_leaf\": 7,\n",
        "    'force_col_wise': 'true'\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "n_rounds = 10000\n",
        "\n",
        "lgb_train = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
        "result = lgb.cv(parameters, lgb_train, n_rounds, folds=skf, callbacks=([lgb.early_stopping(stopping_rounds=20),lgb.log_evaluation(period=10, show_stdv=True)]), eval_train_metric=True, return_cvbooster=True)\n",
        "\n",
        "best_score = 1 - result[\"valid binary_error-mean\"][-1]\n",
        "n_estimators  = int(result[\"cvbooster\"].best_iteration * 1.1)\n",
        "print(\"Accuracy on validation: {:.4f}\".format(best_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ5oxn8Hsx0t",
        "outputId": "3f9eae2a-b1e2-4c21-8837-c942effeea2d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
            "[LightGBM] [Info] Total Bins 226\n",
            "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 10\n",
            "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
            "[LightGBM] [Info] Total Bins 226\n",
            "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 10\n",
            "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
            "[LightGBM] [Info] Total Bins 226\n",
            "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 10\n",
            "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
            "[LightGBM] [Info] Total Bins 226\n",
            "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 10\n",
            "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
            "[LightGBM] [Info] Total Bins 226\n",
            "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
            "[LightGBM] [Info] Start training from score -0.475028\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
            "[LightGBM] [Info] Start training from score -0.471371\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
            "[LightGBM] [Info] Start training from score -0.471371\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
            "[LightGBM] [Info] Start training from score -0.471371\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
            "[LightGBM] [Info] Start training from score -0.477303\n",
            "Training until validation scores don't improve for 20 rounds\n",
            "[10]\tcv_agg's train binary_error: 0.383838 + 0.000580822\tcv_agg's valid binary_error: 0.383837 + 0.00232492\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[20]\tcv_agg's train binary_error: 0.383838 + 0.000580822\tcv_agg's valid binary_error: 0.383837 + 0.00232492\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[30]\tcv_agg's train binary_error: 0.212402 + 0.00197598\tcv_agg's valid binary_error: 0.226721 + 0.0203876\n",
            "[40]\tcv_agg's train binary_error: 0.177891 + 0.00376312\tcv_agg's valid binary_error: 0.202009 + 0.0214937\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[50]\tcv_agg's train binary_error: 0.161897 + 0.00170817\tcv_agg's valid binary_error: 0.187427 + 0.0152827\n",
            "[60]\tcv_agg's train binary_error: 0.150955 + 0.00502877\tcv_agg's valid binary_error: 0.176216 + 0.00859082\n",
            "[70]\tcv_agg's train binary_error: 0.140855 + 0.00610977\tcv_agg's valid binary_error: 0.176235 + 0.014767\n",
            "[80]\tcv_agg's train binary_error: 0.134682 + 0.00781244\tcv_agg's valid binary_error: 0.1695 + 0.0128201\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[90]\tcv_agg's train binary_error: 0.130472 + 0.00622658\tcv_agg's valid binary_error: 0.165012 + 0.0138628\n",
            "[100]\tcv_agg's train binary_error: 0.124017 + 0.00603679\tcv_agg's valid binary_error: 0.158276 + 0.0170292\n",
            "[110]\tcv_agg's train binary_error: 0.120651 + 0.00345011\tcv_agg's valid binary_error: 0.158276 + 0.0194516\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[120]\tcv_agg's train binary_error: 0.119809 + 0.00401038\tcv_agg's valid binary_error: 0.159394 + 0.017795\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Early stopping, best iteration is:\n",
            "[107]\tcv_agg's train binary_error: 0.121493 + 0.00362002\tcv_agg's valid binary_error: 0.156029 + 0.0180884\n",
            "Accuracy on validation: 0.8440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model = lgb.LGBMClassifier(\n",
        "    objective= \"binary\",\n",
        "    learning_rate= 0.01,\n",
        "    num_threads= 10,\n",
        "    metric = 'binary_error',\n",
        "    seed=  random_state,\n",
        "    colsample_bytree= 0.7,\n",
        "    subsample= 0.7,\n",
        "    subsample_freq= 1,\n",
        "    min_data_in_leaf= 7,\n",
        "    force_col_wise= True,\n",
        "    n_estimators  = n_estimators)\n",
        "\n",
        "\n",
        "lgb_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = lgb_model.predict(X_test)\n",
        "submission_data = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': y_pred})\n",
        "submission_data.to_csv(\"/content/drive/MyDrive/MLb4/EDA Titanic/submissionLgb.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPLwxMS8oQFg",
        "outputId": "3c56d048-ef4f-437a-fdec-19b8072a771e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
            "[LightGBM] [Info] Number of positive: 342, number of negative: 549\n",
            "[LightGBM] [Info] Total Bins 226\n",
            "[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288\n",
            "[LightGBM] [Info] Start training from score -0.473288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SUBMISSION SCORE:** 0.7799"
      ],
      "metadata": {
        "id": "76ErhyjLxo1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CatBoost"
      ],
      "metadata": {
        "id": "LnXWnI1zsmMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "import catboost as ctb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UE4pSS2uZkz",
        "outputId": "82abd1d2-a200-4050-f740-07527bc100bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features_indices = np.where(X_train.dtypes != float)[0]"
      ],
      "metadata": {
        "id": "dFnBEy2juou9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "parameters = {\n",
        "    \"loss_function\": \"Logloss\",\n",
        "    \"eval_metric\": \"Accuracy\",\n",
        "    \"iterations\": 10000,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"random_seed\": random_state,\n",
        "    \"od_wait\": 20,\n",
        "    \"od_type\": \"Iter\",\n",
        "    \"thread_count\": 10,\n",
        "    \"subsample\": 0.7,\n",
        "    \"colsample_bylevel\": 0.9\n",
        "}\n",
        "\n",
        "ctb_data = ctb.Pool(X_train,y_train)\n",
        "result = ctb.cv(ctb_data, parameters, folds=skf, seed=random_state, verbose_eval=20, plot=False)\n",
        "\n",
        "best_score = result[\"test-Accuracy-mean\"].max()\n",
        "n_estimators  = int(result[\"test-Accuracy-mean\"].values.argmax() * 1.1)\n",
        "print(\"Accuracy on validation: {:.4f}\".format(best_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz56ghPB2gdL",
        "outputId": "b6cba800-f2b2-4412-b160-a00b7b7f5db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on fold [0/5]\n",
            "0:\tlearn: 0.8188202\ttest: 0.7932961\tbest: 0.7932961 (0)\ttotal: 2.88ms\tremaining: 28.8s\n",
            "20:\tlearn: 0.8244382\ttest: 0.8212291\tbest: 0.8268156 (16)\ttotal: 58.8ms\tremaining: 27.9s\n",
            "\n",
            "bestTest = 0.8268156425\n",
            "bestIteration = 16\n",
            "\n",
            "Training on fold [1/5]\n",
            "0:\tlearn: 0.8246844\ttest: 0.7921348\tbest: 0.7921348 (0)\ttotal: 2.96ms\tremaining: 29.6s\n",
            "20:\tlearn: 0.8316971\ttest: 0.8202247\tbest: 0.8202247 (15)\ttotal: 52.8ms\tremaining: 25.1s\n",
            "\n",
            "bestTest = 0.8202247191\n",
            "bestIteration = 15\n",
            "\n",
            "Training on fold [2/5]\n",
            "0:\tlearn: 0.8190743\ttest: 0.7752809\tbest: 0.7752809 (0)\ttotal: 2.84ms\tremaining: 28.4s\n",
            "20:\tlearn: 0.8359046\ttest: 0.8033708\tbest: 0.8033708 (1)\ttotal: 56.7ms\tremaining: 26.9s\n",
            "\n",
            "bestTest = 0.8033707865\n",
            "bestIteration = 1\n",
            "\n",
            "Training on fold [3/5]\n",
            "0:\tlearn: 0.8106592\ttest: 0.8258427\tbest: 0.8258427 (0)\ttotal: 2.71ms\tremaining: 27.1s\n",
            "20:\tlearn: 0.8246844\ttest: 0.8146067\tbest: 0.8314607 (1)\ttotal: 57.9ms\tremaining: 27.5s\n",
            "\n",
            "bestTest = 0.8314606742\n",
            "bestIteration = 1\n",
            "\n",
            "Training on fold [4/5]\n",
            "0:\tlearn: 0.8190743\ttest: 0.8258427\tbest: 0.8258427 (0)\ttotal: 3.42ms\tremaining: 34.2s\n",
            "20:\tlearn: 0.8246844\ttest: 0.8426966\tbest: 0.8426966 (11)\ttotal: 51.5ms\tremaining: 24.5s\n",
            "40:\tlearn: 0.8260870\ttest: 0.8483146\tbest: 0.8483146 (31)\ttotal: 100ms\tremaining: 24.3s\n",
            "60:\tlearn: 0.8345021\ttest: 0.8483146\tbest: 0.8595506 (45)\ttotal: 155ms\tremaining: 25.3s\n",
            "\n",
            "bestTest = 0.8595505618\n",
            "bestIteration = 45\n",
            "\n",
            "Accuracy on validation: 0.8238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = ctb.CatBoostClassifier(\n",
        "    loss_function = \"Logloss\",\n",
        "    eval_metric = \"Accuracy\",\n",
        "    iterations= 40,\n",
        "    learning_rate= 0.01,\n",
        "    random_seed= random_state,\n",
        "    od_wait = 20,\n",
        "    od_type= \"Iter\",\n",
        "    thread_count= 10,\n",
        "    subsample= 0.7,\n",
        "    colsample_bylevel= 0.9)\n",
        "\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "submission_data = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': y_pred})\n",
        "submission_data.to_csv(\"/content/drive/MyDrive/MLb4/EDA Titanic/submissionCat.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY9Bf5GF2pNW",
        "outputId": "4f3ae585-70a7-4d26-97c8-97bc100b25e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.8193042\ttotal: 766us\tremaining: 29.9ms\n",
            "1:\tlearn: 0.8069585\ttotal: 1.92ms\tremaining: 36.5ms\n",
            "2:\tlearn: 0.8148148\ttotal: 2.97ms\tremaining: 36.7ms\n",
            "3:\tlearn: 0.8159371\ttotal: 3.94ms\tremaining: 35.4ms\n",
            "4:\tlearn: 0.8125701\ttotal: 4.89ms\tremaining: 34.3ms\n",
            "5:\tlearn: 0.8125701\ttotal: 5.6ms\tremaining: 31.7ms\n",
            "6:\tlearn: 0.8103255\ttotal: 6.87ms\tremaining: 32.4ms\n",
            "7:\tlearn: 0.8114478\ttotal: 7.4ms\tremaining: 29.6ms\n",
            "8:\tlearn: 0.8125701\ttotal: 8.41ms\tremaining: 29ms\n",
            "9:\tlearn: 0.8125701\ttotal: 9.31ms\tremaining: 27.9ms\n",
            "10:\tlearn: 0.8148148\ttotal: 10.2ms\tremaining: 26.8ms\n",
            "11:\tlearn: 0.8136925\ttotal: 11.1ms\tremaining: 26ms\n",
            "12:\tlearn: 0.8170595\ttotal: 12.1ms\tremaining: 25.1ms\n",
            "13:\tlearn: 0.8193042\ttotal: 13ms\tremaining: 24.2ms\n",
            "14:\tlearn: 0.8170595\ttotal: 13.6ms\tremaining: 22.7ms\n",
            "15:\tlearn: 0.8170595\ttotal: 14.6ms\tremaining: 21.8ms\n",
            "16:\tlearn: 0.8193042\ttotal: 15.4ms\tremaining: 20.9ms\n",
            "17:\tlearn: 0.8204265\ttotal: 16.2ms\tremaining: 19.8ms\n",
            "18:\tlearn: 0.8215488\ttotal: 17.1ms\tremaining: 18.9ms\n",
            "19:\tlearn: 0.8260382\ttotal: 18.1ms\tremaining: 18.1ms\n",
            "20:\tlearn: 0.8249158\ttotal: 19.1ms\tremaining: 17.3ms\n",
            "21:\tlearn: 0.8260382\ttotal: 20ms\tremaining: 16.3ms\n",
            "22:\tlearn: 0.8260382\ttotal: 21ms\tremaining: 15.5ms\n",
            "23:\tlearn: 0.8260382\ttotal: 21.9ms\tremaining: 14.6ms\n",
            "24:\tlearn: 0.8249158\ttotal: 22.9ms\tremaining: 13.8ms\n",
            "25:\tlearn: 0.8260382\ttotal: 23.9ms\tremaining: 12.9ms\n",
            "26:\tlearn: 0.8271605\ttotal: 24.8ms\tremaining: 11.9ms\n",
            "27:\tlearn: 0.8260382\ttotal: 25.8ms\tremaining: 11.1ms\n",
            "28:\tlearn: 0.8260382\ttotal: 26.8ms\tremaining: 10.2ms\n",
            "29:\tlearn: 0.8260382\ttotal: 27.4ms\tremaining: 9.13ms\n",
            "30:\tlearn: 0.8260382\ttotal: 28.2ms\tremaining: 8.18ms\n",
            "31:\tlearn: 0.8237935\ttotal: 29.2ms\tremaining: 7.29ms\n",
            "32:\tlearn: 0.8237935\ttotal: 30.3ms\tremaining: 6.43ms\n",
            "33:\tlearn: 0.8237935\ttotal: 30.9ms\tremaining: 5.45ms\n",
            "34:\tlearn: 0.8237935\ttotal: 31.7ms\tremaining: 4.53ms\n",
            "35:\tlearn: 0.8260382\ttotal: 32.7ms\tremaining: 3.63ms\n",
            "36:\tlearn: 0.8260382\ttotal: 33.7ms\tremaining: 2.73ms\n",
            "37:\tlearn: 0.8249158\ttotal: 34.6ms\tremaining: 1.82ms\n",
            "38:\tlearn: 0.8249158\ttotal: 35.7ms\tremaining: 914us\n",
            "39:\tlearn: 0.8249158\ttotal: 36.6ms\tremaining: 0us\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SUBMISSION SCORE:** 0.7799"
      ],
      "metadata": {
        "id": "umzw7eum8YVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "\n",
        "\n",
        "- **Random forest**\n",
        "  - Submission Accuracy: 0.76555\n",
        "  - Accuracy on validation: 0.8451\n",
        "- **XGBoost**\n",
        "  - Submission Accuracy: 0.77511\n",
        "  - Accuracy on validation: 0.8417\n",
        "- **LightGBM**\n",
        "  - Submission Accuracy: 0.7799\n",
        "  - Accuracy on validation: 0.8440\n",
        "- **CatBoost**:\n",
        "  - Submission Accuracy: 0.7799\n",
        "  - Accuracy on validation: 0.8238\n",
        "\n"
      ],
      "metadata": {
        "id": "d1E7tQ2C8z0O"
      }
    }
  ]
}